{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:02<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Test score (MAE): 0.1554161289806102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Test score (MAE): 0.16068112561225867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Test score (MAE): 0.16200557977329602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Test score (MAE): 0.16801169055165058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Test score (MAE): 0.15644389039711698\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "test_scores = []\n",
    "for i in range(1,6):\n",
    "    X_train = pd.DataFrame()\n",
    "    X_test = pd.DataFrame()\n",
    "    for gp in tqdm([[4,3,2],[8, 4, 2], [13, 1, 3], [12, 8, 2]]):\n",
    "        new_train = pd.read_csv(f'results/split_spatialS_{i}_{gp}/X_train.csv')\n",
    "        new_test = pd.read_csv(f'results/split_spatialS_{i}_{gp}/X_test.csv')\n",
    "        X_train = pd.concat([X_train, new_train], axis=1)\n",
    "        X_test = pd.concat([X_test, new_test], axis=1)\n",
    "    y_train = pd.read_csv(f'results/split_spatialS_{i}_{gp}/y_train.csv')\n",
    "    y_test = pd.read_csv(f'results/split_spatialS_{i}_{gp}/y_test.csv')\n",
    "    alphas = np.logspace(-6, 6, 20)\n",
    "    print('start')\n",
    "    # Define the model and pipeline\n",
    "    ridge_pipeline = Pipeline([\n",
    "        # ('scaler', StandardScaler()),\n",
    "        ('ridge', RidgeCV(alphas=alphas, cv=5, scoring='neg_mean_absolute_error'))\n",
    "    ])\n",
    "\n",
    "\n",
    "    ridge_pipeline.fit(X_train, y_train)\n",
    "    test_score= np.mean(np.abs(ridge_pipeline.predict(X_test)- y_test))\n",
    "    test_scores.append(test_score)\n",
    "    print(\"Test score (MAE):\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.16051168306298647, 0.002010195603094569)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_scores), np.std(test_scores)/np.sqrt(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this at the top of your evaluation script\n",
    "from scipy.special import sph_harm\n",
    "import numpy as np\n",
    "\n",
    "class SphericalHarmonicsEncoder:\n",
    "    def __init__(self, L=20, output_dim=128):\n",
    "        self.L = L\n",
    "        self.output_dim = output_dim\n",
    "    \n",
    "    def encode_coordinates(self, lat, lon):\n",
    "        \"\"\"\n",
    "        Encode lat/lon using spherical harmonics\n",
    "        \"\"\"\n",
    "        # Handle single values or arrays\n",
    "        lat = np.atleast_1d(lat)\n",
    "        lon = np.atleast_1d(lon)\n",
    "        \n",
    "        lat_rad = np.radians(lat)\n",
    "        lon_rad = np.radians(lon)\n",
    "        \n",
    "        harmonics_features = []\n",
    "        \n",
    "        for i in range(len(lat)):\n",
    "            features_i = []\n",
    "            for l in range(min(self.L + 1, 25)):  # Limit to prevent overflow\n",
    "                for m in range(-l, l + 1):\n",
    "                    try:\n",
    "                        Y_lm = sph_harm(m, l, lon_rad[i], lat_rad[i])\n",
    "                        features_i.extend([Y_lm.real, Y_lm.imag])\n",
    "                    except:\n",
    "                        features_i.extend([0.0, 0.0])  # Fallback for numerical issues\n",
    "            harmonics_features.append(features_i)\n",
    "        \n",
    "        harmonics_array = np.array(harmonics_features)\n",
    "        \n",
    "        # Pad or truncate to desired dimension\n",
    "        if harmonics_array.shape[1] > self.output_dim:\n",
    "            harmonics_array = harmonics_array[:, :self.output_dim]\n",
    "        elif harmonics_array.shape[1] < self.output_dim:\n",
    "            padding = np.zeros((harmonics_array.shape[0], self.output_dim - harmonics_array.shape[1]))\n",
    "            harmonics_array = np.concatenate([harmonics_array, padding], axis=1)\n",
    "        \n",
    "        return harmonics_array\n",
    "\n",
    "def prepare_location_features(df, use_spherical_harmonics=False):\n",
    "    \"\"\"\n",
    "    Prepare location features from DHS data (already processed)\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "    feature_names = []\n",
    "    \n",
    "    # hv025 is already one-hot encoded as hv025_1 and hv025_2\n",
    "    location_columns = ['hv025_1', 'hv025_2']\n",
    "    \n",
    "    # Check if columns exist\n",
    "    missing_cols = [col for col in location_columns if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing location columns: {missing_cols}\")\n",
    "    \n",
    "    # Extract urban/rural features\n",
    "    urban_rural_features = df[location_columns].values\n",
    "    all_features.append(urban_rural_features)\n",
    "    feature_names.extend(['urban_rural_0', 'urban_rural_1'])\n",
    "    \n",
    "    print(f\"Urban/Rural feature distribution:\")\n",
    "    print(f\"  hv025_1 (Urban): {df['hv025_1'].sum()} samples ({df['hv025_1'].mean()*100:.1f}%)\")\n",
    "    print(f\"  hv025_2 (Rural): {df['hv025_2'].sum()} samples ({df['hv025_2'].mean()*100:.1f}%)\")\n",
    "\n",
    "    if use_spherical_harmonics and 'LATNUM' in df.columns and 'LONGNUM' in df.columns:\n",
    "        print('Encoding coordinates with spherical harmonics...')\n",
    "        coord_encoder = SphericalHarmonicsEncoder(L=20, output_dim=256)\n",
    "        \n",
    "        # Extract coordinates\n",
    "        lat = df['LATNUM'].values\n",
    "        lon = df['LONGNUM'].values\n",
    "        \n",
    "        # Encode with spherical harmonics\n",
    "        coord_features = coord_encoder.encode_coordinates(lat, lon)\n",
    "        all_features.append(coord_features)\n",
    "        feature_names.extend([f'coord_sh_{i}' for i in range(coord_features.shape[1])])\n",
    "        \n",
    "        print(f\"  Added spherical harmonics coordinates: {coord_features.shape[1]} features\")\n",
    "\n",
    "        '''\n",
    "        geographic_features = np.column_stack([\n",
    "            np.abs(lat),  # Distance to equator\n",
    "            np.abs(lon),  # Distance to prime meridian\n",
    "            (np.abs(lat) < 23.5).astype(int),  # Tropical zone indicator\n",
    "        ])\n",
    "        all_features.append(geographic_features)\n",
    "        feature_names.extend(['dist_equator', 'dist_prime_meridian', 'tropical_zone'])\n",
    "        \n",
    "        print(f\"  Added basic geographic features: {geographic_features.shape[1]} features\")\n",
    "        '''\n",
    "        \n",
    "    \n",
    "    # Optional: Add additional location features if you want to experiment\n",
    "    additional_features = []\n",
    "    if additional_features:\n",
    "        all_features.extend(additional_features)\n",
    "    \n",
    "    # Combine all features\n",
    "    combined_features = np.concatenate(all_features, axis=1)\n",
    "    \n",
    "    print(f\"  Total location/temporal features: {combined_features.shape[1]}\")\n",
    "    # print(f\"  Feature breakdown: Urban/Rural(2) + Coordinates({coord_features.shape[1] if use_spherical_harmonics and 'LATNUM' in df.columns else 0}) + Geographic(3) + Temporal({temporal_features.shape[1] if use_temporal_features and 'year' in df.columns else 0}) + Additional({sum(f.shape[1] for f in additional_features)})\")\n",
    "    \n",
    "    return combined_features, feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    fold,\n",
    "    model_name,\n",
    "    target=\"\",\n",
    "    use_checkpoint=False,\n",
    "    model_not_named_target=True,\n",
    "    imagery_path=None,\n",
    "    imagery_source=None,\n",
    "    mode=\"temporal\",\n",
    "    model_output_dim=768,\n",
    "    grouped_bands=None,\n",
    "    country=None,\n",
    "    use_location_features=False, # Use Geo info \n",
    "    use_spherical_harmonics=False,\n",
    "):\n",
    "    model_par_dir = \"../model/\"\n",
    "    country_suffix = f'_{country.upper()}' if country else ''\n",
    "\n",
    "    # Build checkpoint filename (pth file) based on mode and target\n",
    "    if use_checkpoint:\n",
    "        named_target = target if model_not_named_target else \"\"\n",
    "        if mode == \"temporal\":\n",
    "            checkpoint = f\"{model_par_dir}{model_name}_temporal_best_{imagery_source}{named_target}{country_suffix}.pth\"\n",
    "        elif mode == \"spatial\":\n",
    "            checkpoint = f\"{model_par_dir}{model_name}_{fold}_{grouped_bands}all_cluster_best_{imagery_source}{named_target}{country_suffix}.pth\"\n",
    "        elif mode == \"one_country\":\n",
    "            checkpoint = f\"{model_par_dir}{model_name}_{fold}_one_country_best_{imagery_source}{named_target}{country_suffix}.pth\"\n",
    "        else:\n",
    "            raise Exception(mode)\n",
    "\n",
    "    print(\n",
    "        f\"Evaluating {model_name} on fold {fold} {f'for country {country_suffix[1:]}' if country else '' } with target {target} using checkpoint {checkpoint if use_checkpoint else 'None'}\"\n",
    "    )\n",
    "\n",
    "    # Modified to adjust the actual number of features/column (target size) of the country-wise model\n",
    "    if use_checkpoint and os.path.exists(checkpoint):\n",
    "        # Load checkpoint to get the actual target size\n",
    "        temp_state = torch.load(checkpoint, map_location='cpu')\n",
    "        actual_target_size = temp_state['model_state_dict']['regression_head.weight'].shape[0]\n",
    "        target_size = actual_target_size\n",
    "        print(f\"Detected target size from checkpoint: {target_size}\")\n",
    "        \n",
    "        # Also set eval_target appropriately\n",
    "        if target == \"\":\n",
    "            eval_target = \"deprived_sev\"  # Use this for single target evaluation\n",
    "    else:\n",
    "        # Original logic for when not using checkpoint\n",
    "        if target == \"\":\n",
    "            eval_target = \"deprived_sev\"\n",
    "            target_size = 99\n",
    "        else:\n",
    "            eval_target = target\n",
    "            target_size = 1 if model_not_named_target else 99\n",
    "\n",
    "    # Determine size of target\n",
    "    '''\n",
    "    if target == \"\":\n",
    "        eval_target = \"deprived_sev\"\n",
    "        target_size = 99\n",
    "    else:\n",
    "        eval_target = target\n",
    "        target_size = 1 if model_not_named_target else 99\n",
    "    '''\n",
    "\n",
    "    # Image Modify based on the Satellite used (L and S)\n",
    "    normalization = 30000.0 if imagery_source == \"L\" else 3000.0\n",
    "    transform_dim = 336 if imagery_source == \"L\" else 994\n",
    "\n",
    "    # DHS data folder\n",
    "    data_folder = \"../../survey_processing/processed_data/\"\n",
    "\n",
    "    # Termporal and Spatial have a different train test spilt\n",
    "    if mode == \"temporal\":\n",
    "        train_df = pd.read_csv(f\"{data_folder}before_2020.csv\")\n",
    "        test_df = pd.read_csv(f\"{data_folder}after_2020.csv\")\n",
    "    else:\n",
    "        train_df = pd.read_csv(f\"{data_folder}train_fold_{fold}{country_suffix}.csv\")\n",
    "        test_df = pd.read_csv(f\"{data_folder}test_fold_{fold}{country_suffix}.csv\")\n",
    "\n",
    "    \n",
    "    # Filter out imagery files that match the source type (L or S)\n",
    "    available_imagery = [\n",
    "        os.path.join(imagery_path, d, f)\n",
    "        for d in os.listdir(imagery_path)\n",
    "        if d[-2] == imagery_source\n",
    "        for f in os.listdir(os.path.join(imagery_path, d))\n",
    "    ]\n",
    "\n",
    "    def is_available(centroid_id):\n",
    "        return any(centroid_id in centroid for centroid in available_imagery)\n",
    "\n",
    "    train_df = train_df[train_df[\"CENTROID_ID\"].apply(is_available)]\n",
    "    test_df = test_df[test_df[\"CENTROID_ID\"].apply(is_available)]\n",
    "    if test_df.empty:\n",
    "        raise Exception(\"Empty test set\")\n",
    "\n",
    "    # Find the imagery file based on the CENTROID_ID\n",
    "    def filter_contains(query):\n",
    "        for item in available_imagery:\n",
    "            if query in item:\n",
    "                return item\n",
    "\n",
    "    train_df[\"imagery_path\"] = train_df[\"CENTROID_ID\"].apply(filter_contains)\n",
    "    train_df = train_df[train_df[\"deprived_sev\"].notna()]\n",
    "    test_df[\"imagery_path\"] = test_df[\"CENTROID_ID\"].apply(filter_contains)\n",
    "    test_df = test_df[test_df[\"deprived_sev\"].notna()]\n",
    "\n",
    "    # Reset indices after all filtering is complete\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "    # NOW extract location features from the final, clean dataframes\n",
    "    if use_location_features:\n",
    "        print(\"Preparing training location features...\")\n",
    "        train_location_features = prepare_location_features(train_df)\n",
    "        \n",
    "        print(\"Preparing test location features...\")\n",
    "        test_location_features = prepare_location_features(test_df)\n",
    "    else:\n",
    "        train_location_features = None\n",
    "        test_location_features = None\n",
    "        print(\"Not using location features\")\n",
    "\n",
    "    # Load image files and preprocess (stack bands, normalize, clip)\n",
    "    def load_and_preprocess_image(path):\n",
    "        with rasterio.open(path) as src:\n",
    "            r = src.read(grouped_bands[0])\n",
    "            g = src.read(grouped_bands[1])\n",
    "            b = src.read(grouped_bands[2])\n",
    "            img = np.dstack((r, g, b))\n",
    "            img = img / normalization * 255.0\n",
    "        img = np.nan_to_num(img, nan=0, posinf=255, neginf=0)\n",
    "        return np.clip(img, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Data are all prepared, now it is time for testing the model\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load pre-trained model from Facebook DINO hub\n",
    "    base_model = (\n",
    "        torch.hub.load(\"facebookresearch/dino:main\", model_name)\n",
    "        if \"dino_\" in model_name\n",
    "        else torch.hub.load(\"facebookresearch/dinov2\", model_name)\n",
    "    )\n",
    "\n",
    "    # Wrapper class to add regression head on top of DINO model\n",
    "    class ViTForRegression(nn.Module):\n",
    "        def __init__(self, base_model):\n",
    "            super().__init__()\n",
    "            self.base_model = base_model\n",
    "            self.regression_head = nn.Linear(model_output_dim, target_size)\n",
    "\n",
    "        def forward(self, pixel_values):\n",
    "            outputs = self.base_model(pixel_values)\n",
    "            return torch.sigmoid(self.regression_head(outputs))\n",
    "\n",
    "        def forward_encoder(self, pixel_values):\n",
    "            return self.base_model(pixel_values)\n",
    "\n",
    "    model = ViTForRegression(base_model)\n",
    "\n",
    "    if use_checkpoint:\n",
    "        state_dict = torch.load(checkpoint)\n",
    "        model.load_state_dict(state_dict[\"model_state_dict\"])\n",
    "\n",
    "    # Dataset class for training and testing\n",
    "    class CustomDataset(Dataset):\n",
    "        def __init__(self, dataframe, transform):\n",
    "            self.dataframe = dataframe\n",
    "            self.transform = transform\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.dataframe)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            item = self.dataframe.iloc[idx]\n",
    "            image = load_and_preprocess_image(item[\"imagery_path\"])\n",
    "            image_tensor = self.transform(Image.fromarray(image))\n",
    "            return image_tensor, item[eval_target]\n",
    "\n",
    "    # Transform image to proper shape and type for model\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.Resize((transform_dim, transform_dim)), transforms.ToTensor()]\n",
    "    )\n",
    "\n",
    "    # Dataloader wraps dataset to allow batch loading\n",
    "    train_dataset = CustomDataset(train_df, transform)\n",
    "    val_dataset = CustomDataset(test_df, transform)\n",
    "\n",
    "    # I believe there is a certain format for the class CustomDataset in order to run\n",
    "    # the function DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Extract features from base model for training data\n",
    "    X_train_visual, y_train = [], []\n",
    "\n",
    "    for images, targets in tqdm(train_loader):\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.base_model(images)\n",
    "        X_train_visual.append(outputs.cpu()[0].numpy())\n",
    "        y_train.append(targets.cpu()[0].numpy())\n",
    "\n",
    "    # Extract features from base model for test data\n",
    "    X_test_visual, y_test = [], []\n",
    "    for images, targets in tqdm(val_loader):\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.base_model(images)\n",
    "        X_test_visual.append(outputs.cpu()[0].numpy())\n",
    "        y_test.append(targets.cpu()[0].numpy())\n",
    "\n",
    "    X_train_visual, y_train = np.array(X_train_visual), np.array(y_train)\n",
    "    X_test_visual, y_test = np.array(X_test_visual), np.array(y_test)\n",
    "\n",
    "    # Combine visual and location features\n",
    "    if use_location_features:\n",
    "        # Since DataLoader processes samples in order and we reset indices,\n",
    "        # location features align directly with visual features\n",
    "        X_train = np.concatenate([X_train_visual, train_location_features], axis=1)\n",
    "        X_test = np.concatenate([X_test_visual, test_location_features], axis=1)\n",
    "        \n",
    "        print(f\"\\nCombined feature dimensions:\")\n",
    "        print(f\"  Visual features: {X_train_visual.shape[1]}\")\n",
    "        print(f\"  Location features: {train_location_features.shape[1]}\")\n",
    "        print(f\"  Total features: {X_train.shape[1]}\")\n",
    "    else:\n",
    "        X_train = X_train_visual\n",
    "        X_test = X_test_visual\n",
    "        print(f\"\\nUsing visual features only: {X_train.shape[1]} dimensions\")\n",
    "    \n",
    "\n",
    "    # Save extracted features and targets to CSV\n",
    "    results_folder = (\n",
    "        f\"modelling/dino/results/split_{mode}{imagery_source}_{fold}_{grouped_bands}\"\n",
    "        f\"{'_loc' if use_location_features else ''}{country_suffix}\"\n",
    "    )\n",
    "    if not os.path.exists(results_folder):\n",
    "        os.makedirs(results_folder)\n",
    "    pd.DataFrame(X_train).to_csv(results_folder + \"X_train.csv\", index=False)\n",
    "    pd.DataFrame(y_train, columns=[\"target\"]).to_csv(results_folder + \"y_train.csv\", index=False)\n",
    "    pd.DataFrame(X_test).to_csv(results_folder + \"X_test.csv\", index=False)\n",
    "    pd.DataFrame(y_test, columns=[\"target\"]).to_csv(results_folder + \"y_test.csv\", index=False)\n",
    "\n",
    "    # Save visual features separately for comparison\n",
    "    pd.DataFrame(X_train_visual).to_csv(results_folder + \"X_train_visual_only.csv\", index=False)\n",
    "    pd.DataFrame(X_test_visual).to_csv(results_folder + \"X_test_visual_only.csv\", index=False)\n",
    "\n",
    "    # Save location features if used\n",
    "    if use_location_features:\n",
    "        pd.DataFrame(train_location_features).to_csv(results_folder + \"X_train_location.csv\", index=False)\n",
    "        pd.DataFrame(test_location_features).to_csv(results_folder + \"X_test_location.csv\", index=False)\n",
    "\n",
    "    # Ridge Regression with cross-validation to evaluate features\n",
    "    alphas = np.logspace(-6, 6, 20)\n",
    "\n",
    "    # Define the pipeline once\n",
    "    ridge_pipeline = Pipeline([\n",
    "        (\"ridge\", RidgeCV(alphas=alphas, cv=5, scoring=\"neg_mean_absolute_error\"))\n",
    "    ])\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # COMPARATIVE ANALYSIS\n",
    "    if use_location_features:\n",
    "        print(\"\\n=== COMPARATIVE ANALYSIS ===\")\n",
    "        \n",
    "        # Visual features only\n",
    "        visual_cv_scores = cross_val_score(\n",
    "            ridge_pipeline, X_train_visual, y_train, cv=kf, scoring=\"neg_mean_absolute_error\"\n",
    "        )\n",
    "        ridge_pipeline.fit(X_train_visual, y_train)\n",
    "        visual_only_score = np.mean(np.abs(ridge_pipeline.predict(X_test_visual) - y_test))\n",
    "        \n",
    "        print(f\"Visual features only:\")\n",
    "        print(f\"  CV MAE: {-visual_cv_scores.mean():.4f} ± {visual_cv_scores.std():.4f}\")\n",
    "        print(f\"  Test MAE: {visual_only_score:.4f}\")\n",
    "        \n",
    "        # Location features only (if meaningful)\n",
    "        if train_location_features.shape[1] > 0:\n",
    "            location_cv_scores = cross_val_score(\n",
    "                ridge_pipeline, train_location_features, y_train, cv=kf, scoring=\"neg_mean_absolute_error\"\n",
    "            )\n",
    "            ridge_pipeline.fit(train_location_features, y_train)\n",
    "            location_only_score = np.mean(np.abs(ridge_pipeline.predict(test_location_features) - y_test))\n",
    "            \n",
    "            print(f\"Location features only:\")\n",
    "            print(f\"  CV MAE: {-location_cv_scores.mean():.4f} ± {location_cv_scores.std():.4f}\")\n",
    "            print(f\"  Test MAE: {location_only_score:.4f}\")\n",
    "        else:\n",
    "            location_only_score = None\n",
    "        \n",
    "        # Combined features\n",
    "        combined_cv_scores = cross_val_score(\n",
    "            ridge_pipeline, X_train, y_train, cv=kf, scoring=\"neg_mean_absolute_error\"\n",
    "        )\n",
    "        ridge_pipeline.fit(X_train, y_train)\n",
    "        combined_score = np.mean(np.abs(ridge_pipeline.predict(X_test) - y_test))\n",
    "        \n",
    "        print(f\"Combined features:\")\n",
    "        print(f\"  CV MAE: {-combined_cv_scores.mean():.4f} ± {combined_cv_scores.std():.4f}\")\n",
    "        print(f\"  Test MAE: {combined_score:.4f}\")\n",
    "        \n",
    "        # Calculate improvement\n",
    "        improvement = visual_only_score - combined_score\n",
    "        improvement_pct = (improvement / visual_only_score) * 100\n",
    "        print(f\"\\nImprovement from adding location: {improvement:.4f} MAE ({improvement_pct:.1f}%)\")\n",
    "        \n",
    "        # Save detailed analysis\n",
    "        analysis_results = {\n",
    "            'visual_only_cv_mae': -visual_cv_scores.mean(),\n",
    "            'visual_only_cv_std': visual_cv_scores.std(),\n",
    "            'visual_only_test_mae': visual_only_score,\n",
    "            'location_only_test_mae': location_only_score,\n",
    "            'combined_cv_mae': -combined_cv_scores.mean(),\n",
    "            'combined_cv_std': combined_cv_scores.std(),\n",
    "            'combined_test_mae': combined_score,\n",
    "            'improvement_mae': improvement,\n",
    "            'improvement_pct': improvement_pct,\n",
    "            'visual_features_count': X_train_visual.shape[1],\n",
    "            'location_features_count': train_location_features.shape[1],\n",
    "            'total_features_count': X_train.shape[1]\n",
    "        }\n",
    "        \n",
    "        pd.DataFrame([analysis_results]).to_csv(results_folder + \"feature_analysis.csv\", index=False)\n",
    "        \n",
    "        # Use combined results for final reporting\n",
    "        final_cv_scores = combined_cv_scores\n",
    "        final_test_score = combined_score\n",
    "    \n",
    "    else:\n",
    "        # Standard evaluation without location features\n",
    "        final_cv_scores = cross_val_score(\n",
    "            ridge_pipeline, X_train, y_train, cv=kf, scoring=\"neg_mean_absolute_error\"\n",
    "        )\n",
    "        ridge_pipeline.fit(X_train, y_train)\n",
    "        final_test_score = np.mean(np.abs(ridge_pipeline.predict(X_test) - y_test))\n",
    "\n",
    "    # Final results\n",
    "    print(f\"\\n=== FINAL EVALUATION RESULTS ===\")\n",
    "    print(\"Cross-validation scores (negative MAE):\", final_cv_scores)\n",
    "    print(\"Mean cross-validation score (negative MAE):\", final_cv_scores.mean())\n",
    "    print(\"Test Score (MAE):\", final_test_score)\n",
    "\n",
    "    return final_test_score\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
